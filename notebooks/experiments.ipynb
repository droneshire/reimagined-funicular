{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import dotenv\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_PLACES_API_KEY\")\n",
    "OPEN_AI_API_KEY = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "\n",
    "CURRENT_DIR = %pwd\n",
    "ROOT_DIR = os.path.dirname(CURRENT_DIR)\n",
    "SRC_DIR = os.path.join(ROOT_DIR, \"src\")\n",
    "\n",
    "sys.path.append(SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ross/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ross/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from searches.google_places import GoogleMapsAPI, GooglePlacesAPI\n",
    "from searches.util import extract_city, get_city_center_coordinates\n",
    "from text_util import clean_text, parse_itenerary_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"location\": \"South Beach Miami, FL\",\n",
    "    \"number_of_people\": 6,\n",
    "    \"date\": \"November 2026\",\n",
    "    \"duration_days\": 3,\n",
    "    \"group_type\": \"bachelorette party\",\n",
    "    \"description\": (\n",
    "        \"include boutique hotel options must 4 stars higher onsite spa beach clubs djs\"\n",
    "        \"day high end nightclubs list least six restaurant options dinner include least \"\n",
    "        \"one nice steakhouse one nice sushi restaurant\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create itinerary: provide only names for places listed in google places for breakfast, morning activity, lunch, afternoon activity, dinner and evening activity. return only the day and the name: 3 day bachelorette party south beach miami fl 6 people november 2026 enjoy include boutique hotel options must 4 stars higher onsite spa beach clubs djsday high end nightclubs list least six restaurant options dinner include least one nice steakhouse one nice sushi restaurant\n"
     ]
    }
   ],
   "source": [
    "PROMPT_START = \"\"\"Create itinerary: provide only names\n",
    "for places listed in google places for breakfast,\n",
    "morning activity, lunch, afternoon activity, dinner and\n",
    "evening activity. return only the day and the name:\n",
    "\"\"\".replace(\n",
    "    \"\\n\", \" \"\n",
    ")\n",
    "\n",
    "PROMPT_TEMPLATE = f\"\"\"“{inputs['duration_days']}” day\n",
    "“{inputs['group_type']}” to “{inputs['location']}” for “{inputs['number_of_people']}”\n",
    "people in “{inputs['date']}” that enjoy “{inputs['description']}”\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"{PROMPT_START}{clean_text(PROMPT_TEMPLATE)}\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimize Prompt Length**\n",
    "\n",
    "The cleaned_text contains a lot of detailed requirements for the itinerary. While detail is good, ensure that every word is necessary to fulfill the request. Extra tokens increase cost without adding value.\n",
    "\n",
    "**Adjust Temperature**\n",
    "\n",
    "A temperature of 1 is the most creative setting, leading to more varied outputs. However, for generating an itinerary based on specific criteria, a lower temperature might produce more consistent and focused results, potentially reducing the need for additional tokens to clarify or correct the output.\n",
    "\n",
    "**Refine Max Tokens**\n",
    "\n",
    "The max_tokens setting determines the maximum length of the generated response. If you find that the responses are consistently shorter than your limit, you can lower max_tokens to save on costs. Analyze the average length of the responses you're getting and adjust accordingly.\n",
    "\n",
    "**Use top_p Wisely**\n",
    "\n",
    "Setting top_p=1 means the model considers all possible next tokens at each step, which is fine for maximizing creativity but might not be necessary for your use case. Adjusting top_p to a lower value could make the model's responses more focused and concise, potentially reducing token usage.\n",
    "\n",
    "**Penalties**\n",
    "\n",
    "You've set frequency_penalty and presence_penalty to 0, which is neutral and doesn't influence the model's token choices. Depending on the variety you need in the responses, tweaking these values can help manage repetition and ensure the uniqueness of the places listed, potentially making the responses more efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Day 1:', 'Breakfast - Bitch Don’t Kill My Vibe Coffee Shop', 'Morning activity - South Beach Kayak', 'Lunch - Prime Fish', 'Afternoon activity - Miami Beach Bike Rides', 'Dinner - Red, the Steakhouse', 'Evening activity - LIV Nightclub', '', 'Day 2:', 'Breakfast - The Local House', 'Morning activity - Art Deco Historic District Walking Tour', 'Lunch - Katsuya South Beach', 'Afternoon activity - Jet Ski South Beach', 'Dinner - KYU', 'Evening activity - STORY Nightclub', '', 'Day 3:', 'Breakfast - News Cafe', 'Morning activity - SoBe Ice Arena', 'Lunch - Cibo Wine Bar', 'Afternoon activity - Relax at The Standard Spa', 'Dinner - Smith & Wollensky', 'Evening activity - WALL Lounge']\n",
      "Estimated total cost for 1000000 requests: $4522.00\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=OPEN_AI_API_KEY)\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "print(response.choices[0].message.content.split(\"\\n\"))\n",
    "\n",
    "# Extract token usage from the response\n",
    "completion_tokens = response.usage.completion_tokens\n",
    "prompt_tokens = response.usage.prompt_tokens\n",
    "total_tokens = completion_tokens + prompt_tokens\n",
    "\n",
    "# Cost estimation for 1,000,000 requests\n",
    "total_requests = 1_000_000\n",
    "total_tokens_for_all_requests = total_tokens * total_requests\n",
    "\n",
    "training_cost_per_million_tokens = 8.00\n",
    "input_usage_cost_per_million_tokens = 3.00\n",
    "output_usage_cost_per_million_tokens = 6.00\n",
    "\n",
    "total_cost = (total_tokens_for_all_requests / 1_000_000) * (\n",
    "    training_cost_per_million_tokens\n",
    "    + input_usage_cost_per_million_tokens\n",
    "    + output_usage_cost_per_million_tokens\n",
    ")\n",
    "\n",
    "print(f\"Estimated total cost for {total_requests} requests: ${total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not parse line: Breakfast - Bitch Don’t Kill My Vibe Coffee Shop\n",
      "Could not parse line: Morning activity - South Beach Kayak\n",
      "Could not parse line: Lunch - Prime Fish\n",
      "Could not parse line: Afternoon activity - Miami Beach Bike Rides\n",
      "Could not parse line: Dinner - Red, the Steakhouse\n",
      "Could not parse line: Evening activity - LIV Nightclub\n",
      "Could not parse line: Breakfast - The Local House\n",
      "Could not parse line: Morning activity - Art Deco Historic District Walking Tour\n",
      "Could not parse line: Lunch - Katsuya South Beach\n",
      "Could not parse line: Afternoon activity - Jet Ski South Beach\n",
      "Could not parse line: Dinner - KYU\n",
      "Could not parse line: Evening activity - STORY Nightclub\n",
      "Could not parse line: Breakfast - News Cafe\n",
      "Could not parse line: Morning activity - SoBe Ice Arena\n",
      "Could not parse line: Lunch - Cibo Wine Bar\n",
      "Could not parse line: Afternoon activity - Relax at The Standard Spa\n",
      "Could not parse line: Dinner - Smith & Wollensky\n",
      "Could not parse line: Evening activity - WALL Lounge\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Extract the itinerary content from the response\n",
    "itinerary_content = response.choices[0].message.content\n",
    "data = parse_itenerary_content(itinerary_content)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_places = GooglePlacesAPI(api_key=GOOGLE_API_KEY)\n",
    "google_maps = GoogleMapsAPI(api_key=GOOGLE_API_KEY)\n",
    "gmaps = googlemaps.Client(key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (543217234.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[8], line 20\u001b[0;36m\u001b[0m\n\u001b[0;31m    try:\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "city_coordinates = get_city_center_coordinates(inputs[\"location\"])\n",
    "print(f\"{inputs['location']} coordinates: {city_coordinates}\")\n",
    "\n",
    "itinerary_place_details = []\n",
    "nearby_place_details = {}\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        result = gmaps.places(query=row[\"Place\"], location=city_coordinates)\n",
    "    except:\n",
    "        print(f\"Unable to get places info for {row['Place']}\")\n",
    "        continue\n",
    "\n",
    "    if not result or result.get(\"status\") != \"OK\":\n",
    "        print(f\"Unable to get places info for {row['Place']}\")\n",
    "        continue\n",
    "\n",
    "    place_result = result[\"results\"][0]\n",
    "    itinerary_place_details.append(place_result)\n",
    "\n",
    "    try:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Num results: {len(itinerary_place_details)}\")\n",
    "for item in itinerary_place_details:\n",
    "    print(item[\"name\"])\n",
    "    # print(json.dumps(item, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMA03IFWmqQKkWDwPiQuD4a",
   "provenance": [
    {
     "file_id": "1ew1f_XkMbNKy3rsJ9WuRr3vfsWskEU54",
     "timestamp": 1712353675429
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
