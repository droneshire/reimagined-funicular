{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import dotenv\n",
    "import googlemaps\n",
    "import pandas as pd\n",
    "from openai import OpenAI\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_PLACES_API_KEY\")\n",
    "OPEN_AI_API_KEY = os.getenv(\"OPEN_AI_API_KEY\")\n",
    "\n",
    "CURRENT_DIR = %pwd\n",
    "ROOT_DIR = os.path.dirname(CURRENT_DIR)\n",
    "SRC_DIR = os.path.join(ROOT_DIR, \"src\")\n",
    "\n",
    "sys.path.append(SRC_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from searches.google_places import GoogleMapsAPI, GooglePlacesAPI\n",
    "from searches.util import (\n",
    "    extract_city,\n",
    "    get_city_center_coordinates,\n",
    "    miles_to_meters,\n",
    "    meters_to_miles,\n",
    ")\n",
    "from text_util import clean_text, parse_itenerary_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"location\": \"South Beach Miami, FL\",\n",
    "    \"number_of_people\": 6,\n",
    "    \"date\": \"November 2026\",\n",
    "    \"duration_days\": 3,\n",
    "    \"group_type\": \"bachelorette party\",\n",
    "    \"description\": (\n",
    "        \"include boutique hotel options must 4 stars higher onsite spa beach clubs djs\"\n",
    "        \"day high end nightclubs list least six restaurant options dinner include least \"\n",
    "        \"one nice steakhouse one nice sushi restaurant\"\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT_START = \"\"\"Create itinerary: provide only names\n",
    "for places listed in google places for breakfast,\n",
    "morning activity, lunch, afternoon activity, dinner and\n",
    "evening activity. return only the day and the name:\n",
    "\"\"\".replace(\n",
    "    \"\\n\", \" \"\n",
    ")\n",
    "\n",
    "PROMPT_TEMPLATE = f\"\"\"“{inputs['duration_days']}” day\n",
    "“{inputs['group_type']}” to “{inputs['location']}” for “{inputs['number_of_people']}”\n",
    "people in “{inputs['date']}” that enjoy “{inputs['description']}”\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"{PROMPT_START}{clean_text(PROMPT_TEMPLATE)}\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimize Prompt Length**\n",
    "\n",
    "The cleaned_text contains a lot of detailed requirements for the itinerary. While detail is good, ensure that every word is necessary to fulfill the request. Extra tokens increase cost without adding value.\n",
    "\n",
    "**Adjust Temperature**\n",
    "\n",
    "A temperature of 1 is the most creative setting, leading to more varied outputs. However, for generating an itinerary based on specific criteria, a lower temperature might produce more consistent and focused results, potentially reducing the need for additional tokens to clarify or correct the output.\n",
    "\n",
    "**Refine Max Tokens**\n",
    "\n",
    "The max_tokens setting determines the maximum length of the generated response. If you find that the responses are consistently shorter than your limit, you can lower max_tokens to save on costs. Analyze the average length of the responses you're getting and adjust accordingly.\n",
    "\n",
    "**Use top_p Wisely**\n",
    "\n",
    "Setting top_p=1 means the model considers all possible next tokens at each step, which is fine for maximizing creativity but might not be necessary for your use case. Adjusting top_p to a lower value could make the model's responses more focused and concise, potentially reducing token usage.\n",
    "\n",
    "**Penalties**\n",
    "\n",
    "You've set frequency_penalty and presence_penalty to 0, which is neutral and doesn't influence the model's token choices. Depending on the variety you need in the responses, tweaking these values can help manage repetition and ensure the uniqueness of the places listed, potentially making the responses more efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=OPEN_AI_API_KEY)\n",
    "\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    ")\n",
    "print(response.choices[0].message.content.split(\"\\n\"))\n",
    "\n",
    "# Extract token usage from the response\n",
    "completion_tokens = response.usage.completion_tokens\n",
    "prompt_tokens = response.usage.prompt_tokens\n",
    "total_tokens = completion_tokens + prompt_tokens\n",
    "\n",
    "# Cost estimation for 1,000,000 requests\n",
    "total_requests = 1_000_000\n",
    "total_tokens_for_all_requests = total_tokens * total_requests\n",
    "\n",
    "training_cost_per_million_tokens = 8.00\n",
    "input_usage_cost_per_million_tokens = 3.00\n",
    "output_usage_cost_per_million_tokens = 6.00\n",
    "\n",
    "total_cost = (total_tokens_for_all_requests / 1_000_000) * (\n",
    "    training_cost_per_million_tokens\n",
    "    + input_usage_cost_per_million_tokens\n",
    "    + output_usage_cost_per_million_tokens\n",
    ")\n",
    "\n",
    "print(f\"Estimated total cost for {total_requests} requests: ${total_cost:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as T\n",
    "import re\n",
    "def parse_itenerary_day(lines: T.List[str]) -> T.List[T.Tuple[str, str]]:\n",
    "    day_plan = []\n",
    "    # This pattern is designed to capture two groups separated by various delimiters\n",
    "    pattern = re.compile(r\"\\-?\\s*([\\w\\s]+?)\\s*(?::|at|-)\\s*([\\w\\s'&]+)\")\n",
    "\n",
    "    for line in lines:\n",
    "        match = pattern.match(line)\n",
    "        if match:\n",
    "            activity_type, place = match.groups()\n",
    "            activity_type = activity_type.strip()\n",
    "            place = place.split(\"(\")[0].strip()  # Removes anything within parentheses\n",
    "            day_plan.append((activity_type, place))\n",
    "        else:\n",
    "            print(f\"Could not parse line: {line}\")\n",
    "\n",
    "    return day_plan\n",
    "\n",
    "\n",
    "def parse_itenerary_content(content: str) -> T.List[T.Dict[str, str]]:\n",
    "    # Split the content into days and activities\n",
    "    days = content.split(\"\\n\\n\")\n",
    "    data = []\n",
    "    for day in days:\n",
    "        lines = day.split(\"\\n\")\n",
    "        day_number = lines[0].split(\" \")[1]\n",
    "        day_plan = parse_itenerary_day(lines[1:])\n",
    "        for activity_type, place in day_plan:\n",
    "            data.append(\n",
    "                {\"Day\": day_number, \"Activity Type\": activity_type, \"Place\": place}\n",
    "            )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the itinerary content from the response\n",
    "itinerary_content = response.choices[0].message.content\n",
    "data = parse_itenerary_content(itinerary_content)\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "google_places = GooglePlacesAPI(api_key=GOOGLE_API_KEY)\n",
    "google_maps = GoogleMapsAPI(api_key=GOOGLE_API_KEY)\n",
    "gmaps = googlemaps.Client(key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_coordinates = get_city_center_coordinates(inputs[\"location\"])\n",
    "print(f\"{inputs['location']} coordinates: {city_coordinates}\")\n",
    "keyword = \"breakfast\"\n",
    "\n",
    "itinerary_place_details = []\n",
    "nearby_place_details = {}\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        result = gmaps.places(query=row[\"Place\"], location=city_coordinates)\n",
    "    except:\n",
    "        print(f\"Unable to get places info for {row['Place']}\")\n",
    "        continue\n",
    "\n",
    "    if not result or result.get(\"status\") != \"OK\":\n",
    "        print(f\"Unable to get places info for {row['Place']}\")\n",
    "        continue\n",
    "\n",
    "    place_result = result[\"results\"][0]\n",
    "    itinerary_place_details.append(place_result)\n",
    "\n",
    "    radius_meters = miles_to_meters(1.0)\n",
    "\n",
    "    print(f\"Getting nearby places for {row['Place']} at {place_result['geometry']['location']}\")\n",
    "    try:\n",
    "        nearby_places = gmaps.places_nearby(\n",
    "            location=place_result[\"geometry\"][\"location\"],\n",
    "            radius=radius_meters,\n",
    "            keyword=keyword if keyword else None,\n",
    "            type=place_result[\"types\"][0] if place_result[\"types\"] else None,\n",
    "        )\n",
    "    except:\n",
    "        print(f\"Unable to get nearby places info for {row['Place']}\")\n",
    "        continue\n",
    "\n",
    "    if not nearby_places or nearby_places.get(\"status\") != \"OK\":\n",
    "        print(f\"Unable to get nearby places info for {row['Place']}\")\n",
    "        continue\n",
    "\n",
    "    nearby_place_details[row[\"Place\"]] = nearby_places[\"results\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Num results: {len(itinerary_place_details)}\")\n",
    "for item in itinerary_place_details:\n",
    "    print(item[\"name\"])\n",
    "    nearby_names = [i[\"name\"] for i in nearby_place_details.get(item[\"name\"], [])]\n",
    "    for name in nearby_names:\n",
    "        print(f\"  - {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMA03IFWmqQKkWDwPiQuD4a",
   "provenance": [
    {
     "file_id": "1ew1f_XkMbNKy3rsJ9WuRr3vfsWskEU54",
     "timestamp": 1712353675429
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
